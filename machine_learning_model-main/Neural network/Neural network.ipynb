{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e179b11a-a230-40f7-8e2d-741020d0405b",
   "metadata": {},
   "source": [
    "### Data soruce:\n",
    "https://www.freecodecamp.org/news/how-to-build-your-first-neural-network-to-predict-house-prices-with-keras-f8db83049159/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76451085-39ad-46e4-aefe-91382d3efff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd1b560-e6aa-445c-8b4d-e5834bb08839",
   "metadata": {},
   "source": [
    "### X features and y output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e67382b-9ce2-496a-8507-112b4ded4c6f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X= np.array([[185.32,  12.69],\n",
    "       [259.92,  11.87],\n",
    "       [231.01,  14.41],\n",
    "       [175.37,  11.72],\n",
    "       [187.12,  14.13],\n",
    "       [225.91,  12.1 ],\n",
    "       [208.41,  14.18],\n",
    "       [207.08,  14.03],\n",
    "       [280.6 ,  14.23],\n",
    "       [202.87,  12.25],\n",
    "       [196.7 ,  13.54],\n",
    "       [270.31,  14.6 ],\n",
    "       [192.95,  15.2 ],\n",
    "       [213.57,  14.28],\n",
    "       [164.47,  11.92],\n",
    "       [177.26,  15.04],\n",
    "       [241.77,  14.9 ],\n",
    "       [237.  ,  13.13],\n",
    "       [219.74,  13.87],\n",
    "       [266.39,  13.25],\n",
    "       [270.45,  13.95],\n",
    "       [261.96,  13.49],\n",
    "       [243.49,  12.86],\n",
    "       [220.58,  12.36],\n",
    "       [163.59,  11.65],\n",
    "       [244.76,  13.33],\n",
    "       [271.19,  14.84],\n",
    "       [201.99,  15.39],\n",
    "       [229.93,  14.56],\n",
    "       [204.97,  12.28],\n",
    "       [173.19,  12.22],\n",
    "       [231.51,  11.95],\n",
    "       [152.69,  14.83],\n",
    "       [163.42,  13.3 ],\n",
    "       [215.95,  13.98],\n",
    "       [218.04,  15.25],\n",
    "       [251.3 ,  13.8 ],\n",
    "       [233.33,  13.53],\n",
    "       [280.24,  12.41],\n",
    "       [243.02,  13.72],\n",
    "       [155.67,  12.68],\n",
    "       [275.17,  14.64],\n",
    "       [151.73,  12.69],\n",
    "       [151.32,  14.81],\n",
    "       [164.9 ,  11.73],\n",
    "       [282.55,  13.28],\n",
    "       [192.98,  11.7 ],\n",
    "       [202.6 ,  12.96],\n",
    "       [220.67,  11.53],\n",
    "       [169.97,  12.34],\n",
    "       [209.47,  12.71],\n",
    "       [232.8 ,  12.64],\n",
    "       [272.8 ,  15.35],\n",
    "       [158.02,  12.34],\n",
    "       [226.01,  14.58],\n",
    "       [158.64,  12.24],\n",
    "       [211.66,  14.17],\n",
    "       [271.95,  14.97],\n",
    "       [257.16,  11.71],\n",
    "       [281.85,  13.96],\n",
    "       [161.63,  12.52],\n",
    "       [233.8 ,  13.04],\n",
    "       [210.29,  14.72],\n",
    "       [261.24,  13.69],\n",
    "       [256.98,  13.12],\n",
    "       [281.56,  13.92],\n",
    "       [280.64,  11.68],\n",
    "       [269.16,  13.74],\n",
    "       [246.34,  12.27],\n",
    "       [224.07,  12.66],\n",
    "       [164.24,  11.51],\n",
    "       [272.42,  14.18],\n",
    "       [177.68,  12.53],\n",
    "       [212.86,  14.77],\n",
    "       [165.88,  15.37],\n",
    "       [277.43,  12.48],\n",
    "       [236.51,  12.94],\n",
    "       [244.14,  11.85],\n",
    "       [213.45,  13.85],\n",
    "       [234.57,  14.27],\n",
    "       [270.34,  12.47],\n",
    "       [170.68,  13.06],\n",
    "       [226.79,  15.34],\n",
    "       [245.92,  14.45],\n",
    "       [281.32,  12.57],\n",
    "       [185.03,  13.19],\n",
    "       [189.88,  14.1 ],\n",
    "       [278.48,  12.11],\n",
    "       [219.92,  14.21],\n",
    "       [216.58,  15.15],\n",
    "       [249.48,  15.03],\n",
    "       [165.09,  12.28],\n",
    "       [158.87,  14.82],\n",
    "       [279.98,  11.56],\n",
    "       [256.55,  14.41],\n",
    "       [272.61,  12.58],\n",
    "       [246.49,  12.45],\n",
    "       [160.26,  14.48],\n",
    "       [155.7 ,  14.3 ],\n",
    "       [188.27,  13.45],\n",
    "       [270.36,  12.47],\n",
    "       [213.22,  12.92],\n",
    "       [175.7 ,  13.39],\n",
    "       [174.52,  14.7 ],\n",
    "       [233.  ,  12.63],\n",
    "       [281.37,  12.88],\n",
    "       [240.62,  14.43],\n",
    "       [185.81,  11.55],\n",
    "       [270.5 ,  15.33],\n",
    "       [172.98,  12.11],\n",
    "       [208.41,  13.89],\n",
    "       [283.51,  15.35],\n",
    "       [283.36,  12.48],\n",
    "       [230.85,  13.24],\n",
    "       [181.24,  11.76],\n",
    "       [172.78,  12.93],\n",
    "       [161.88,  12.1 ],\n",
    "       [156.03,  13.99],\n",
    "       [216.52,  12.47],\n",
    "       [221.06,  13.2 ],\n",
    "       [238.99,  15.23],\n",
    "       [197.69,  14.08],\n",
    "       [179.55,  15.26],\n",
    "       [233.39,  12.13],\n",
    "       [184.7 ,  12.14],\n",
    "       [174.18,  12.73],\n",
    "       [261.11,  13.33],\n",
    "       [187.42,  13.18],\n",
    "       [186.1 ,  14.43],\n",
    "       [157.94,  12.66],\n",
    "       [193.64,  12.23],\n",
    "       [249.65,  12.22],\n",
    "       [190.56,  11.73],\n",
    "       [252.  ,  12.96],\n",
    "       [238.55,  12.37],\n",
    "       [152.94,  12.79],\n",
    "       [255.17,  14.85],\n",
    "       [197.09,  14.89],\n",
    "       [156.8 ,  13.59],\n",
    "       [184.75,  13.26],\n",
    "       [179.92,  15.07],\n",
    "       [190.79,  15.28],\n",
    "       [164.73,  13.22],\n",
    "       [209.87,  14.34],\n",
    "       [196.58,  13.47],\n",
    "       [159.51,  12.74],\n",
    "       [247.87,  11.92],\n",
    "       [212.44,  12.45],\n",
    "       [172.34,  11.99],\n",
    "       [259.87,  14.25],\n",
    "       [201.23,  13.07],\n",
    "       [248.34,  13.92],\n",
    "       [273.66,  15.18],\n",
    "       [215.09,  14.14],\n",
    "       [223.53,  12.74],\n",
    "       [211.22,  14.38],\n",
    "       [224.61,  14.03],\n",
    "       [215.75,  15.31],\n",
    "       [254.82,  12.02],\n",
    "       [259.9 ,  15.17],\n",
    "       [260.25,  12.87],\n",
    "       [199.67,  12.47],\n",
    "       [157.52,  13.39],\n",
    "       [264.81,  14.58],\n",
    "       [239.4 ,  14.89],\n",
    "       [238.98,  12.39],\n",
    "       [258.43,  12.97],\n",
    "       [270.16,  12.81],\n",
    "       [162.41,  14.42],\n",
    "       [164.53,  14.98],\n",
    "       [205.61,  14.62],\n",
    "       [157.1 ,  13.68],\n",
    "       [241.38,  12.02],\n",
    "       [232.13,  12.07],\n",
    "       [191.04,  12.96],\n",
    "       [233.64,  12.02],\n",
    "       [174.95,  14.63],\n",
    "       [246.64,  13.32],\n",
    "       [188.07,  14.27],\n",
    "       [213.16,  12.75],\n",
    "       [268.08,  12.31],\n",
    "       [258.58,  13.97],\n",
    "       [237.21,  14.23],\n",
    "       [251.02,  15.02],\n",
    "       [274.28,  12.52],\n",
    "       [172.12,  15.09],\n",
    "       [177.52,  12.39],\n",
    "       [258.71,  15.36],\n",
    "       [264.01,  13.57],\n",
    "       [200.71,  15.45],\n",
    "       [249.37,  14.02],\n",
    "       [151.5 ,  12.28],\n",
    "       [151.82,  15.13],\n",
    "       [181.92,  12.18],\n",
    "       [228.65,  12.31],\n",
    "       [223.78,  15.3 ],\n",
    "       [266.63,  12.48],\n",
    "       [273.68,  13.1 ],\n",
    "       [220.61,  12.8 ],\n",
    "       [284.99,  12.73]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e964c8b-c9b6-40ba-a517-aec91874de03",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Y= np.array([[1.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [1.],\n",
    "       [1.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [1.],\n",
    "       [1.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [1.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [1.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [1.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [1.],\n",
    "       [1.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [1.],\n",
    "       [1.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [1.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [1.],\n",
    "       [1.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [1.],\n",
    "       [0.],\n",
    "       [1.],\n",
    "       [1.],\n",
    "       [0.],\n",
    "       [1.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [1.],\n",
    "       [1.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [1.],\n",
    "       [1.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [1.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [1.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [1.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [1.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [1.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [1.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [1.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [1.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [1.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [1.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [1.],\n",
    "       [1.],\n",
    "       [1.],\n",
    "       [1.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [1.],\n",
    "       [1.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [1.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [1.],\n",
    "       [1.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [1.],\n",
    "       [0.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94840256-fbab-43ad-9f5a-060f609661eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " x=[[185.32  12.69]\n",
      " [259.92  11.87]\n",
      " [231.01  14.41]\n",
      " [175.37  11.72]] y=[[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "print(f\" x={X[:4]} y={Y[:4]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0aeafd-e326-414e-a14f-aaade747454d",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e54ae59-241a-448c-8680-3f66303d54d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature Max, Min pre normalization: 284.99, 151.32\n",
      "Duration    Max, Min pre normalization: 15.45, 11.51\n",
      "Temperature Max, Min post normalization: 1.66, -1.69\n",
      "Duration    Max, Min post normalization: 1.79, -1.70\n"
     ]
    }
   ],
   "source": [
    "print(f\"Temperature Max, Min pre normalization: {np.max(X[:,0]):0.2f}, {np.min(X[:,0]):0.2f}\")\n",
    "print(f\"Duration    Max, Min pre normalization: {np.max(X[:,1]):0.2f}, {np.min(X[:,1]):0.2f}\")\n",
    "norm_l = tf.keras.layers.Normalization(axis=-1)\n",
    "norm_l.adapt(X)  # learns mean, variance\n",
    "Xn = norm_l(X)\n",
    "print(f\"Temperature Max, Min post normalization: {np.max(Xn[:,0]):0.2f}, {np.min(Xn[:,0]):0.2f}\")\n",
    "print(f\"Duration    Max, Min post normalization: {np.max(Xn[:,1]):0.2f}, {np.min(Xn[:,1]):0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d838ea-4d7a-4a36-990f-0b7b7b2a1603",
   "metadata": {},
   "source": [
    "### W and B parameter\n",
    "column of w = node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8861a204-c20c-48fc-b168-45b33db2f948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-8.93  0.29 12.9 ]\n",
      " [-0.1  -7.32 10.81]] [-9.82 -9.28  0.96] [[-31.18]\n",
      " [-27.59]\n",
      " [-32.56]] [15.41]\n"
     ]
    }
   ],
   "source": [
    "W1_tmp = np.array( [[-8.93,  0.29, 12.9 ], \n",
    "                    [-0.1,  -7.32, 10.81]] )\n",
    "b1_tmp = np.array( [-9.82, -9.28,  0.96] )\n",
    "W2_tmp = np.array( [[-31.18], [-27.59], [-32.56]] )\n",
    "b2_tmp = np.array( [15.41] )\n",
    "print(W1_tmp, b1_tmp, W2_tmp, b2_tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4001e2ef-1792-4104-b2a9-43e52eb90e49",
   "metadata": {},
   "source": [
    "### Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33ed0f2f-2bae-4789-8bf6-d1e0a438db01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#binary  ifx<0 return 0,  ifx>0 return 1\n",
    "def binaryStep(x):\n",
    "    return np.heaviside(x,1)\n",
    "\n",
    "#sigmoid\n",
    "def g(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "#linear\n",
    "def linear(z):\n",
    "    return z\n",
    "\n",
    "#Tanh (nonlinear activation function, outputs between -1 and 1)\n",
    "def tanh(z):\n",
    "    return np.tanh(z)\n",
    "\n",
    "#ReLu --> Return 0 if the input is negative otherwise return the input as it is.\n",
    "def relu(x):\n",
    "    return max(0.0,x)\n",
    "\n",
    "#Leaky ReLU\n",
    "def Leaky_relu(x):\n",
    "    if x>0 :\n",
    "        return x\n",
    "    else :\n",
    "        return 0.01*x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "caaaf33e-4908-49e5-afaa-38573dfb25c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_dense(a_in, W, b):\n",
    "    units = W.shape[1]  #3\n",
    "    a_out = np.zeros(units) #(0,0,0)\n",
    "    for j in range(units):     #for j in range(3):          \n",
    "        w = W[:,j]             # w = W[0:the end,0] --> [-8.93,  0.29, 12.9 ]  \n",
    "                               # w = W[0:the end,1] --> [-0.1,  -7.32, 10.81]\n",
    "        z = np.dot(w, a_in) + b[j]         #(  x(row) * w(column) + .....)+ b\n",
    "        a_out[j] = g(z)               \n",
    "    return(a_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fae1fd-fca9-459e-87e9-db518897add9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Number of layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3de05ce1-e702-458a-aebf-ef63eaba7255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_sequential(x, W1, b1, W2, b2):\n",
    "    a1 = my_dense(x,  W1, b1)\n",
    "    a2 = my_dense(a1, W2, b2)\n",
    "    return(a2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb04efe-3f2d-4ca7-b76d-3e03a6e1bdb0",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32c860c9-3475-41ea-ac6d-10ae2b0f1142",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_predict(X, W1, b1, W2, b2):\n",
    "    m = X.shape[0]  #200 row\n",
    "    p = np.zeros((m,1)) #create (200 row, 1 column)\n",
    "    for i in range(m): # for i in range(200)\n",
    "        p[i,0] = my_sequential(X[i], W1, b1, W2, b2)  #\n",
    "    return(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7e99517-846c-401b-914d-e20d9eb225cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def norm(x):\n",
    "#     for i in range(x.shape[1]): #for i in range(1)\n",
    "#         x[:, i] = (x[:, i] - np.min(x[:, i]))/(np.max(x[:, i]) - np.min(x[:, i]))\n",
    "#         # x[all row ,0] -->200\n",
    "#                            200\n",
    "#                            300\n",
    "#          #x[all row ,1] -->13.9\n",
    "#                            17\n",
    "#                            20\n",
    "#     return x\n",
    "\n",
    "# def norm(x):\n",
    "#     vector_norm = np.linalg.norm(x)\n",
    "#     return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "742cac7b-303c-4cb2-8bbb-f2be6160ae13",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tst = np.array([\n",
    "    [200,13.9],  # postive example\n",
    "    [200,17],\n",
    "    [300,20]])   # negative example\n",
    "X_tstn = norm_l(X_tst)  # remember to normalize\n",
    "predictions = my_predict(X_tstn, W1_tmp, b1_tmp, W2_tmp, b2_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0d92ef7-38d8-4ffb-9b49-8d11baf72a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decisions = \n",
      "[[1.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "yhat = np.zeros_like(predictions)\n",
    "for i in range(len(predictions)): #predictions = X_tst\n",
    "    if predictions[i] >= 0.5:\n",
    "        yhat[i] = 1\n",
    "    else:\n",
    "        yhat[i] = 0\n",
    "print(f\"decisions = \\n{yhat}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
